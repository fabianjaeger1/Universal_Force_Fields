{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import bz2\n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import psutil\n",
    "# import csv\n",
    "import pickle\n",
    "# import pandas as pd\n",
    "from pymatgen.core import Structure\n",
    "import math\n",
    "pd.options.display.max_colwidth = 100\n",
    "# sns.set_theme(style = 'ticks')\n",
    "\n",
    "# st = sns.axes_style(\"ticks\")\n",
    "# # sns.set(style = st,palette = sns.color_palette(\"muted\"), rc={'figure.figsize': (8,8)})\n",
    "# sns.set(style = st,palette = sns.color_palette(\"muted\"))\n",
    "# sns.set(style = st,palette = sns.color_palette(\"tab10\"))\n",
    "\n",
    "# # np.set_printoptions(threshold=np.inf)\n",
    "# #sns.set(color_codes = True)\n",
    "# plt.rcParams.update({\n",
    "#     \"text.usetex\": True,\n",
    "#     \"font.family\": \"serif\",\n",
    "#     \"font.sans-serif\": [\"Computer Modern Roman\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import psutil\n",
    "# import csv\n",
    "import pickle\n",
    "# import pandas as pd\n",
    "from pymatgen.core import Structure\n",
    "import math\n",
    "pd.options.display.max_colwidth = 100\n",
    "# sns.set_theme(style = 'ticks')\n",
    "\n",
    "# st = sns.axes_style(\"ticks\")\n",
    "# # sns.set(style = st,palette = sns.color_palette(\"muted\"), rc={'figure.figsize': (8,8)})\n",
    "# sns.set(style = st,palette = sns.color_palette(\"muted\"))\n",
    "# sns.set(style = st,palette = sns.color_palette(\"tab10\"))\n",
    "\n",
    "# # np.set_printoptions(threshold=np.inf)\n",
    "   \n",
    "# #sns.set(color_codes = True)\n",
    "# plt.rcParams.update({\n",
    "#     \"text.usetex\": True,\n",
    "#     \"font.family\": \"serif\",\n",
    "#     \"font.sans-serif\": [\"Computer Modern Roman\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_arr_to_csv(arr, path):\n",
    "#     with open(path, mode = 'w', newline = '') as csvfile:\n",
    "#         writer = csv.writer(csvfile)\n",
    "#         writer.writerows(arr)\n",
    "\n",
    "# def read_from_csv(path):\n",
    "#     with open(path, mode = 'r') as csvfile:\n",
    "#         reader = csv.reader(csvfile)\n",
    "#         arr = [row for row in reader]\n",
    "#     return arr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_forces(var_forces):\n",
    "    arr = []\n",
    "    for index, force_arr in enumerate(var_forces):\n",
    "        if len(force_arr) > 1:\n",
    "            # print(force_arr)\n",
    "            # print(len(force_arr))\n",
    "            for i in range(len(force_arr)):\n",
    "                # print(force_arr[i])\n",
    "                arr.append(force_arr[i])\n",
    "        else:\n",
    "            arr.append(force_arr)\n",
    "    return arr\n",
    "\n",
    "def get_coordinate(array, axis = 'x'):\n",
    "\n",
    "    switcher = {\n",
    "        \"x\": int(0),\n",
    "        \"y\": int(1),\n",
    "        \"z\": int(2),\n",
    "    }\n",
    "\n",
    "    switch = switcher.get(axis, \"nothing\")\n",
    "    coordinate_arr = [arr[switch] for arr in tqdm(array)] \n",
    "    print(coordinate_arr)\n",
    "    return coordinate_arr\n",
    "\n",
    "\n",
    "def magnitude_vec(vector):\n",
    "    print(\"Vector: {}\".format(vector)) \n",
    "    # print(sum(pow(element, 2) for element in vector))\n",
    "    # print([element for element in vector])\n",
    "    print(math.sqrt(sum(np.power(element, 2) for element in vector)))\n",
    "    return math.sqrt(sum(np.power(element, 2) for element in vector))\n",
    "\n",
    "    # return math.sqrt(sum(np.power(element, 2) for element in vector))\n",
    "\n",
    "def abs_forces_per_run(var_forces):\n",
    "    arr = []\n",
    "    for index, force_arr in enumerate(var_forces):\n",
    "        if len(force_arr) > 1:\n",
    "            print(force_arr)\n",
    "            sum_arr = 0\n",
    "            for i in range(len(force_arr)):\n",
    "                print(force_arr[i])\n",
    "                sum_arr += magnitude_vec(force_arr[i])\n",
    "            arr.append(sum_arr)\n",
    "        else:\n",
    "            arr.append(magnitude_vec(force_arr[0]))\n",
    "    return arr\n",
    "\n",
    "\n",
    "def import_df(path):\n",
    "    df = pd.read_pickle(\"{}\".format(path))\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_cum_count(df):\n",
    "    cum_series = df.groupby('run').cumcount()\n",
    "    cum_series = cum_series.astype(str)\n",
    "    df['run'] = df['run'] + \"_\" + cum_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stress_cut(stress_arr, component, cutoff):\n",
    "    stress_comp = stress_arr[:, component[0], component[1]]\n",
    "    stress_comp_cut = stress_comp[np.where(abs(stress_comp) < cutoff)]\n",
    "    print(\"Min: {}, Max: {}\".format(np.min(stress_comp_cut), np.max(stress_comp_cut)))\n",
    "    return stress_comp_cut\n",
    "\n",
    "def stress_cut_hist(stress_arr, component, cutoff, nr_bin, y_lim):\n",
    "    stress_comp = stress_arr[:, component[0], component[1]]\n",
    "\n",
    "    switcher = {\n",
    "        0: \"x\",\n",
    "        1: \"y\",\n",
    "        2: \"z\"\n",
    "    }\n",
    "\n",
    "    axis_1 = switcher.get(component[0], \"nothing\")\n",
    "    axis_2 = switcher.get(component[1], \"nothing\")\n",
    "\n",
    "    print('Chosen component: {}'.format(axis_1 + axis_2))\n",
    "    \n",
    "    stress_arr_cut = stress_cut(stress_arr, component, cutoff)\n",
    "\n",
    "    plt.xlabel(\"Stress_{}\".format(axis_1 + axis_2))\n",
    "    \n",
    "    plt.hist(stress_arr_cut, bins = nr_bin)\n",
    "    plt.tight_layout()\n",
    "    if y_lim!= None:\n",
    "        plt.ylim([0, y_lim])\n",
    "        plt.savefig(\"Figures/stress_{}{}_cut.pdf\".format(axis_1, axis_2))\n",
    "    else:\n",
    "        plt.savefig(\"Figures/stress_{}{}.pdf\".format(axis_1, axis_2))\n",
    "\n",
    "\n",
    "def stress_cut_hist_comb(stress_arr, cutoff, nr_bin, ylim):\n",
    "    stress_xx = stress_arr[:, 0, 0]\n",
    "    stress_xy = stress_arr[:, 0, 1]\n",
    "    stress_yx = stress_arr[:, 1, 0]\n",
    "    stress_yy = stress_arr[:, 1, 1]\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2)\n",
    "    axs[0, 0].hist(stress_xx, bins = nr_bin)\n",
    "    # axs[0, 0].set_title('Axis [0,0]')\n",
    "    axs[0, 1].hist(stress_xy, bins = nr_bin)\n",
    "    # axs[0, 1].set_title('Axis [0,1]')\n",
    "    axs[1, 0].hist(stress_yx, bins = nr_bin)\n",
    "    # axs[1, 0].set_title('Axis [1,0]')\n",
    "    axs[1, 1].hist(stress_yy, bins = nr_bin)\n",
    "\n",
    "    plt.setp(axs, xlim = [-400, 400], ylim=[0, ylim])\n",
    "\n",
    "    # axs[0, 0].set_ylim([0, ylim])\n",
    "    # axs[0, 1].set_ylim\n",
    "    # axs[1, 1].set_title('Axis [1,1]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(directory, overwrite = False):\n",
    "    if overwrite == True:\n",
    "        print(\"Number of files in directory: {}\".format(len(os.listdir(directory))))\n",
    "        files = os.listdir(directory)\n",
    "        print(files)\n",
    "\n",
    "        df_data = pd.DataFrame(columns=['run', 'energy', 'forces', 'stress_xx', 'stress_xy', 'stress_xz', 'stress_yx', 'stress_yy', 'stress_yz', 'stress_zx', 'stress_zy', 'stress_zz'])\n",
    "\n",
    "        for file_name in files:\n",
    "            print(\"Current file selected: {}\".format(file_name))\n",
    "            print('RAM memory % used:', psutil.virtual_memory()[2])\n",
    "            # Getting usage of virtual_memory in GB ( 4th field)\n",
    "            print('RAM Used (GB):', psutil.virtual_memory()[3]/1000000000)\n",
    "            with bz2.BZ2File(\"{}/{}\".format(directory,file_name)) as file:\n",
    "                for line in file:\n",
    "                    line = line.decode().strip()\n",
    "                    if line in {\"[\", \"]\"}:\n",
    "                        continue\n",
    "                    if line.endswith(\" \"):\n",
    "                        line = line[:-1]\n",
    "                    entity =json.loads(line)\n",
    "                    for run in entity.keys():\n",
    "                        for item in entity[run]:\n",
    "                            # print(item)\n",
    "                            struc = Structure.from_dict(item['structure'])\n",
    "                            forces = item['forces']\n",
    "                    \n",
    "                            stress = item['stress']\n",
    "                            energy = item['energy']\n",
    "                            \n",
    "                            # if energy > 0:\n",
    "                            #     print(\"There is a positive energy entry: {}\".format(energy))\n",
    "                            \n",
    "                            data_run = pd.DataFrame({'run': run,\n",
    "                                                        \"structure\": [struc],\n",
    "                                                        \"energy\": energy, \n",
    "                                                        \"forces\": [forces], \n",
    "                                                        'stress_xx': [stress[0][0]], 'stress_xy': [stress[0][1]], 'stress_xz':[stress[0][2]], \n",
    "                                                        'stress_yx': [stress[1][0]], 'stress_yy': [stress[1][1]], 'stress_yz': [stress[1][2]], \n",
    "                                                        'stress_zx': [stress[2][0]], 'stress_zy': [stress[2][1]], 'stress_zz': [stress[2][2]]})\n",
    "\n",
    "                            data_run = pd.DataFrame(data_run)\n",
    "                            df_data = pd.concat([df_data, data_run])\n",
    "\n",
    "        df_data.reset_index(inplace = True, drop = True)\n",
    "\n",
    "        add_cum_count(df_data)\n",
    "        \n",
    "        df_data.memory_usage()\n",
    "        df_data.to_pickle(\"df_data.pkl\")\n",
    "\n",
    "    elif overwrite == False:\n",
    "       df_data = import_df('df_data.pkl')\n",
    "\n",
    "    return df_data\n",
    "\n",
    "def create_arr(directory):\n",
    "\n",
    "    print(\"Number of files in directory: {}\".format(len(os.listdir(directory))))\n",
    "    files = os.listdir(directory)\n",
    "    print(files)\n",
    "\n",
    "    dict_id = {}\n",
    "    # df_id = pd.DataFrame(columns = [\"id\", \"run\"])\n",
    "\n",
    "    struc_arr = []\n",
    "    stress_arr = []\n",
    "    energy_arr = []\n",
    "    forces_arr = []\n",
    "    index = 0\n",
    "\n",
    "    for file_name in tqdm(files):\n",
    "        print(\"Current file selected: {}\".format(file_name))\n",
    "        \n",
    "        with bz2.BZ2File(\"{}/{}\".format(directory,file_name)) as file:\n",
    "            for line in tqdm(file):\n",
    "                line = line.decode().strip()\n",
    "                if line in {\"[\", \"]\"}:\n",
    "                    continue\n",
    "                if line.endswith(\" \"):\n",
    "                    line = line[:-1]\n",
    "                entity =json.loads(line)\n",
    "                for run in entity.keys():\n",
    "                    for item in entity[run]:\n",
    "                        # print(len(entity[run]))\n",
    "                        # struc = Structure.from_dict(item['structure'])\n",
    "                        struc = item['structure']\n",
    "                        forces = item['forces']\n",
    "                        stress = item['stress']\n",
    "                        energy = item['energy']\n",
    "                        \n",
    "                        dict_id[index] = run\n",
    "\n",
    "                        stress_arr.append(stress)\n",
    "                        forces_arr.append(forces)\n",
    "                        energy_arr.append(energy)\n",
    "                        struc_arr.append(struc)\n",
    "                        \n",
    "                        with open('log.txt', 'a') as f:\n",
    "                            f.write(\"{}-{}: Energy: {}, Forces: {}, Stress: {} + \\n\".format(run, index, energy, forces, stress))\n",
    "                        index += 1\n",
    "\n",
    "    return struc_arr, energy_arr, stress_arr, forces_arr, dict_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struc_arr, energy_arr, stress_arr, forces_arr, dict_id = create_arr(\"geo_opt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain Structure Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_struc_data(directory):\n",
    "    #! CAN PROBABLY BE DELETED (SEE METHOD CREATE ARR)\n",
    "\n",
    "    print(\"Number of files in directory: {}\".format(len(os.listdir(directory))))\n",
    "    files = os.listdir(directory)\n",
    "    print(files)\n",
    "\n",
    "    # dict_id = {}\n",
    "    # df_id = pd.DataFrame(columns = [\"id\", \"run\"])\n",
    "    struc = []\n",
    "\n",
    "    for file_name in tqdm(files[:2]):\n",
    "        print(\"Current file selected: {}\".format(file_name))\n",
    "        with bz2.BZ2File(\"{}/{}\".format(directory,file_name)) as file:\n",
    "            for line in tqdm(file):\n",
    "                line = line.decode().strip()\n",
    "                if line in {\"[\", \"]\"}:\n",
    "                    continue\n",
    "                if line.endswith(\" \"):\n",
    "                    line = line[:-1]\n",
    "                entity =json.loads(line)\n",
    "                for run in entity.keys():\n",
    "                    # i  = 0\n",
    "                    for item in entity[run]:\n",
    "                        # print(len(entity[run]))\n",
    "                        # struc = Structure.from_dict(item['structure'])\n",
    "                        # print(run['structure'])\n",
    "                        print(item['structure'])\n",
    "                        st = item['structure']\n",
    "                        # st = item['structure'][i]\n",
    "\n",
    "                        struc.append(st)\n",
    "                        \n",
    "\n",
    "    return struc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# struc_arr = get_struc_data(\"geo_opt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(struc_arr))\n",
    "test_str = Structure.from_dict(struc_arr[0])\n",
    "print(test_str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split val, test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test_val = train_test_split(data, test_size=0.1, train_size=0.9, random_state=1, shuffle=True)\n",
    "test, val = train_test_split(test_val, test_size=0.5, train_size=0.5, random_state=2, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save and load data arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_arr_json(arr, path):\n",
    "    with open(path, mode = 'w') as line:\n",
    "        json.dump(arr, line)\n",
    "\n",
    "def read_arr_json(path):\n",
    "    with open(path, mode = 'r') as line:\n",
    "        arr = json.load(line)\n",
    "    return np.array(arr)\n",
    "\n",
    "def save_id_dict(dict, path):\n",
    "    # BEWARE JSON turns keys into strings and not int\n",
    "    with open(path, 'w') as line:\n",
    "        json.dump(dict, line)\n",
    "\n",
    "def load_id_dict(path):\n",
    "    with open(path, 'r') as line:\n",
    "        arr = json.load(line)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_arr_json(struc_arr, \"struc_arr.txt\")\n",
    "save_arr_json(forces_arr, \"forces_arr.txt\")\n",
    "save_arr_json(stress_arr, \"stress_arr.txt\")\n",
    "save_arr_json(energy_arr, \"energy_arr.txt\")\n",
    "save_id_dict(dict_id, \"id_run.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/4g615zb158g4h62pfnnjmy0m0000gn/T/ipykernel_72226/1067728059.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(arr)\n"
     ]
    }
   ],
   "source": [
    "struc_arr = read_arr_json(\"struc_arr.txt\")\n",
    "forces_arr = read_arr_json(\"forces_arr.txt\")\n",
    "energy_arr = read_arr_json(\"energy_arr.txt\")\n",
    "stress_arr = read_arr_json(\"stress_arr.txt\")\n",
    "id_run = load_id_dict(\"id_run.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str = Structure.from_dict(struc_arr[0])\n",
    "print(test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_atoms_per_run = [np.shape(x)[0] for x in tqdm(forces_arr[:])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reformat kbar to Gpa for stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 1D or 2D array, got 3D array instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m stress_arr_ref \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39m-\u001b[39m\u001b[39m0.1\u001b[39m\u001b[39m*\u001b[39mstress_arr\u001b[39m/\u001b[39m\u001b[39m160.21766208\u001b[39m) \u001b[39m#kbar to GPa for m3gnet\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# print(np.shape(stress_arr_ref))\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# save_arr_json(stress_arr_ref, \"stress_arr_gpa.txt\")\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# print(stress_arr_ref[0])\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m np\u001b[39m.\u001b[39;49msavetxt(\u001b[39m\"\u001b[39;49m\u001b[39mstress_arr_gpa.txt\u001b[39;49m\u001b[39m\"\u001b[39;49m, stress_arr_ref)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msavetxt\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda/envs/master_thesis/lib/python3.11/site-packages/numpy/lib/npyio.py:1537\u001b[0m, in \u001b[0;36msavetxt\u001b[0;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[1;32m   1535\u001b[0m \u001b[39m# Handle 1-dimensional arrays\u001b[39;00m\n\u001b[1;32m   1536\u001b[0m \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m-> 1537\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1538\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExpected 1D or 2D array, got \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39mD array instead\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m X\u001b[39m.\u001b[39mndim)\n\u001b[1;32m   1539\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1540\u001b[0m     \u001b[39m# Common case -- 1d array of numbers\u001b[39;00m\n\u001b[1;32m   1541\u001b[0m     \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mnames \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 1D or 2D array, got 3D array instead"
     ]
    }
   ],
   "source": [
    "# REFORMAT THE STRUCTURE ARRAY TO GPA AND SAVE IT\n",
    "stress_arr_ref = np.array(-0.1*stress_arr/160.21766208) #kbar to GPa for m3gnet\n",
    "np.savetxt('stress_arr_gpa.txt', stress_arr_ref.reshape(-1, stress_arr_ref.shape[-1])) #reshape into a 2D array to save it"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the GPa stress array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5889788, 3, 3)\n",
      "(5889788, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "stress_arr_gpa = np.loadtxt('stress_arr_gpa.txt').reshape(np.shape(energy_arr)[0], 3, 3) #reshape the imported 2d array into the 3d array\n",
    "print(np.shape(stress_arr_gpa))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reformat Key dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_reformated = {}\n",
    "for key, val in id_run.items():\n",
    "    # print(key, val)\n",
    "    try:\n",
    "        id_reformated[val].append(key)\n",
    "    except:\n",
    "        id_reformated[val] = [key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_id_dict(id_reformated, \"id_run_reformat.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(id_run.keys()))\n",
    "print(len(id_reformated.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_reformated = load_id_dict(\"id_run_reformat.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.shape(forces_arr))\n",
    "# print(np.shape(stress_arr))\n",
    "# print(stress_arr[1])\n",
    "# print(forces_arr[0])\n",
    "# print(np.shape(energy_arr))\n",
    "\n",
    "# print(id_run[\"14000\"])\n",
    "\n",
    "# print(len(new_id_run.keys()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_1d_energy(arr, name, xrange = [-160,100]):\n",
    "    fig, ax = plt.subplots()\n",
    "    n, bins, patches = ax.hist(arr, bins = 1000)\n",
    "    ax.set_xlabel(\"{}\".format(\"Energy\"))\n",
    "    ax.set_xlim(xrange)\n",
    "    ax.set_ylabel(\"Counts\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"Figures/{}.pdf\".format(name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outlier Removal energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_arr = np.array(energy_arr)\n",
    "\n",
    "id_outlier_energy = np.where((energy_arr < 0.0) & (energy_arr > -150))[0]\n",
    "id_outlier_stress = np.where((stress_arr[:,0,0] < 50) & (stress_arr[:, 0,0] > -50))[0]\n",
    "\n",
    "print(id_outlier_energy)\n",
    "print(id_outlier_stress)\n",
    "\n",
    "outlier_id = np.intersect1d(id_outlier_energy, id_outlier_stress)\n",
    "\n",
    "energy_arr_cut = energy_arr[id_outlier_energy]\n",
    "\n",
    "energy_arr_cut\n",
    "\n",
    "\n",
    "energy_arr_cut_complete = energy_arr[outlier_id]\n",
    "stress_arr_cut_complete = stress_arr[outlier_id, 0, 0]\n",
    "\n",
    "\n",
    "# print(np.shape(energy_arr))\n",
    "print(np.shape(energy_arr_cut))\n",
    "print(np.shape(energy_arr_cut_complete))\n",
    "\n",
    "\n",
    "print(np.shape(stress_arr_cut_complete))\n",
    "\n",
    "\n",
    "\n",
    "print(np.max(energy_arr_cut_complete))\n",
    "\n",
    "\n",
    "# arr = set([id_run[x] for x in id_outlier])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Energy per atom histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_per_atoms = np.divide(energy_arr, nr_atoms_per_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers(arr, larger_than, smaller_than):\n",
    "\n",
    "    if smaller_than == None and larger_than != None:\n",
    "        id_outliers = np.where(arr > larger_than)[0]\n",
    "        # id_outliers_top = np.where(arr < smaller_than)[0]\n",
    "        # id_outliers = np.concatenate((id_outliers_bottom, id_outliers_top))\n",
    "    elif larger_than and smaller_than != None:\n",
    "        id_outliers_bottom = np.where(arr > larger_than)[0]\n",
    "        id_outliers_top = np.where(arr < smaller_than)[0]\n",
    "        id_outliers = np.concatenate((id_outliers_bottom, id_outliers_top))\n",
    "\n",
    "    outlier_energy_names = set([id_run[\"{}\".format(x)] for x in tqdm(id_outliers)])\n",
    "\n",
    "    return outlier_energy_names, id_outliers\n",
    "\n",
    "def remove_outliers(arr, cut_top, cut_bot):\n",
    "    cropped_arr = [x for x in arr if x <= cut_top and  x >= cut_bot]\n",
    "    id_outliers_bottom = np.where(arr > cut_bot)[0]\n",
    "    id_outliers_top = np.where(arr < cut_top)[0]\n",
    "    id_outliers = np.intersect1d(id_outliers_bottom, id_outliers_top)\n",
    "    return cropped_arr, id_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_per_atom_cropped, id_out_energy =remove_outliers(energy_per_atoms, cut_top = 0, cut_bot = -12.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(energy_per_atom_cropped))\n",
    "print(np.shape(id_out_energy))\n",
    "\n",
    "print(np.shape(energy_per_atoms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_1d_energy(energy_per_atom_cropped, \"energy_per_atom\", xrange = [-20,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_arr_cut = stress_arr[id_out_energy]\n",
    "# print(np.shape(stress_arr_cut))\n",
    "# print(np.shape(energy_arr))\n",
    "\n",
    "# print(np.shape(stress_arr))\n",
    "# print(np.shape(id_out_energy))\n",
    "np.min(stress_arr_cut)\n",
    "np.max(stress_arr_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_cut_hist_comb(stress_arr_cut, cutoff = 500, nr_bin=1000, ylim = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_cut_hist(stress_arr_cut, component = [0,0], cutoff = 10000, nr_bin = 100, y_lim = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_cut_hist(stress_arr_cut, component = [0,0], cutoff = 10000, nr_bin = 100, y_lim = 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find positive energy outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_energy_pos, id_energy_outliers_pos = find_outliers(energy_arr,larger_than= 0, smaller_than = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(id_energy_outliers_pos))\n",
    "print(np.min(energy_arr[id_energy_outliers_pos]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"energy_outliers_pos.txt\", \"w\") as f:\n",
    "    for s in outlier_energy_pos:\n",
    "        f.write(str(s) +\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_arr = np.array(energy_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_outliers_bottom = np.where(energy_arr > 0.0)[0]\n",
    "id_outliers_top = np.where(energy_arr < -150)[0]\n",
    "\n",
    "\n",
    "energy_outliers = np.concatenate((id_outliers_bottom, id_outliers_top))\n",
    "\n",
    "print(id_outliers_bottom)\n",
    "print(id_outliers_top)\n",
    "print(energy_outliers)\n",
    "\n",
    "\n",
    "print(energy_outliers[0])\n",
    "energy_name = id_run[\"{}\".format(energy_outliers[0])]\n",
    "\n",
    "\n",
    "outlier_energy_names = set([id_run[\"{}\".format(x)] for x in tqdm(energy_outliers)])\n",
    "print(outlier_energy_names)\n",
    "\n",
    "# outlier_energy_name = set([x for x in energy_outliers])\n",
    "\n",
    "\n",
    "# print(energy_arr[317573])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(outlier_energy_names)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_test = [id_run[\"{}\".format(x)] for x in tqdm(energy_outliers[0:200])]\n",
    "# set_test = [x for x in tqdm(energy_outliers[:200])]\n",
    "set_test = [id_run[\"{}\".format(x)] for x in tqdm(energy_outliers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_test = list(set(set_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_arr_cut = stress_arr[id_outlier, :, :]\n",
    "print(np.shape(stress_arr_cut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(energy_arr_cut)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Convention"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Energy: eV\n",
    "Force: eV/Angstrom\n",
    "Stress: technically eV/Angstrom^2 but are something kbar from VASP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram2d_stress_energy(energy_arr_cut, stress_arr_cut, component, bin, stress_lim):\n",
    "\n",
    "    stress_arr_cut_comp = stress_arr_cut[:, component[0], component[1]]\n",
    "\n",
    "    switcher = {\n",
    "        0: \"x\",\n",
    "        1: \"y\",\n",
    "        2: \"z\"\n",
    "    }\n",
    "\n",
    "    axis_1 = switcher.get(component[0], \"nothing\")\n",
    "    axis_2 = switcher.get(component[1], \"nothing\")\n",
    "\n",
    "    print('Chosen component: {}'.format(axis_1 + axis_2))\n",
    "    plt.hist2d(energy_arr_cut, stress_arr_cut_comp, bins = bin)\n",
    "    plt.xlabel(\"Energy\")\n",
    "    plt.ylabel(\"Stress_{}\".format(axis_1 + axis_2))\n",
    "    plt.ylim(stress_lim[0],stress_lim[1])\n",
    "    plt.savefig(\"Figures/energy_stress_{}_hist.pdf\".format(axis_1 + axis_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_hist(x, y, ax, ax_histx, ax_histy):\n",
    "    # no labels\n",
    "    ax_histx.tick_params(axis=\"x\", labelbottom=False)\n",
    "    ax_histy.tick_params(axis=\"y\", labelleft=False)\n",
    "\n",
    "    # the scatter plot:\n",
    "    ax.scatter(x, y, s = 1)\n",
    "    sns.kdeplot(x=x, y=y, levels=5, color=\"w\", linewidths=1, ax = ax)\n",
    "\n",
    "    # now determine nice limits by hand:\n",
    "    binwidth = 0.25\n",
    "    xymax = max(np.max(np.abs(x)), np.max(np.abs(y)))\n",
    "    lim = (int(xymax/binwidth) + 1) * binwidth\n",
    "\n",
    "    bins = np.arange(-lim, lim + binwidth, binwidth)\n",
    "    ax_histx.hist(x, bins=bins)\n",
    "    ax_histy.hist(y, bins=bins, orientation='horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(stress_arr_cut_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "g = sns.jointplot(x=energy_arr_cut_complete, y=stress_arr_cut_complete, kind=\"kde\", color=\"#4CB391\", bins=25)\n",
    "g.ax_joint.set_ylim([-5,5]) \n",
    "# g.ax_joint.set_xscale('log')\n",
    "# g.ax_joint.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # plt.set_yscale('log')\n",
    "# plt.yscale('log')\n",
    "# sns.jointplot(x=energy_arr_cut_complete, y=stress_arr_cut_complete, kind=\"hex\", color=\"#4CB391\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(x = energy_arr_cut_complete, y = stress_arr_cut_complete, level  = 2, color = 'r', linewidth = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "g = sns.JointGrid(x = energy_arr_cut_complete, y = stress_arr_cut_complete space=0)\n",
    "g.plot_joint(sns.kdeplot,\n",
    "             fill=True, clip=((2200, 6800), (10, 25)),\n",
    "             thresh=0, levels=100, cmap=\"rocket\")\n",
    "g.plot_marginals(sns.histplot, color=\"#03051A\", alpha=1, bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a square Figure.\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "# Add a gridspec with two rows and two columns and a ratio of 1 to 4 between\n",
    "# the size of the marginal axes and the main axes in both directions.\n",
    "# Also adjust the subplot parameters for a square plot.\n",
    "gs = fig.add_gridspec(2, 2,  width_ratios=(4, 1), height_ratios=(1, 4),\n",
    "                      left=0.1, right=0.9, bottom=0.1, top=0.9,\n",
    "                      wspace=0.05, hspace=0.05)\n",
    "# Create the Axes.\n",
    "ax = fig.add_subplot(gs[1, 0])\n",
    "ax_histx = fig.add_subplot(gs[0, 0], sharex=ax)\n",
    "ax_histy = fig.add_subplot(gs[1, 1], sharey=ax)\n",
    "\n",
    "ax.set_xlim([-160,10])\n",
    "ax.set_ylim([-50,50])\n",
    "# Draw the scatter plot and marginals.\n",
    "scatter_hist(energy_arr_cut_complete, stress_arr_cut_complete, ax, ax_histx, ax_histy)\n",
    "fig.savefig(\"Figures/{}.pdf\".format(\"hist2d_stress_energy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram2d_stress_energy(energy_arr_cut, stress_arr_cut, component = [1,1], bin =  1000, stress_lim = [-50, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(energy_arr_cut, stress_arr_cut[:,0,0], bins  =100)\n",
    "plt.ylim([-0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x=energy_arr_cut_complete, y=stress_arr_cut_complete, kind = 'hex')\n",
    "# plt.ylim[1,1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cropping Energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_energies = [x for x in energy_arr if x <= 0 and  x >= -180]\n",
    "cropped_energies_top = [x for x in energy_arr if x >= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_1d_energy(cropped_energies, \"energy_hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(cropped_energies)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forces_arr_concat = [np.array(x) for x in forces_arr]\n",
    "print(np.shape(forces_arr_concat))\n",
    "forces_arr_concat = np.concatenate(forces_arr_concat, axis = 0)\n",
    "print(np.shape(forces_arr_concat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the concatenate force arr\n",
    "np.savetxt('force_arr_concat.txt', forces_arr_concat, delimiter = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the concatenated force arr from the txt file\n",
    "force_arr_concat = np.genfromtxt(\"force_arr_concat.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain Forces for the individual axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forces_arr_x = forces_arr_concat[:,0]\n",
    "forces_arr_y = forces_arr_concat[:,1]\n",
    "forces_arr_z = forces_arr_concat[:,2]\n",
    "# forces_arr_y = forces_arr_concat[:,1]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outlier Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_outliers():\n",
    "#     cut_force_top =  1\n",
    "#     cut_force_bot = -1\n",
    "#     cut_energy_bot = -150\n",
    "#     cut_energy_top = 0\n",
    "#     cut_stress_top = 1\n",
    "#     cut_stress_bot = -1\n",
    "\n",
    "#     out_energy_id = np.where(energy_arr < cut_energy_top)\n",
    "#     # out_force_id = np.where(np.logical_and(forces_arr < cut_force_top, forces_arr > cut_force_bot))[0]\n",
    "\n",
    "#     print(out_energy_id)\n",
    "#     print(energy_arr[0:10])\n",
    "# get_outliers()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stress Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_arr = np.array(stress_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_cut_hist(stress_arr, component = [0,1], cutoff = 50, nr_bin = 1000, y_lim = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_cut_hist(stress_arr, component = [0,0], cutoff = 50, nr_bin = 1000, y_lim = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stress_arr = np.array(stress_arr)\n",
    "energy_arr =np.array(energy_arr)\n",
    "# print(type(energy_arr))\n",
    "print(np.shape(energy_arr))\n",
    "print(np.shape(stress_arr))\n",
    "\n",
    "stress_xx = stress_arr[:,0,0]\n",
    "stress_xy = stress_arr[:,0,1]\n",
    "stress_xz = stress_arr[:,0,2]\n",
    "stress_yx = stress_arr[:,1,0]\n",
    "stress_yy = stress_arr[:,1,1]\n",
    "stress_yz = stress_arr[:,1,2]\n",
    "print(np.shape(stress_xx))\n",
    "\n",
    "# np.mean(stress_xx)\n",
    "# outliers = np.where(stress_xx > 1)\n",
    "# print(outliers[0])\n",
    "\n",
    "stress_arr_cut_xx = stress_xx[np.where(abs(stress_xx) < 3)]\n",
    "energy_arr_cut_stress_xx = energy_arr[np.where(abs(stress_xx) < 1)]\n",
    "\n",
    "\n",
    "print(np.shape(energy_arr_cut_stress_xx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(energy_arr_cut_stress_xx)\n",
    "np.shape(stress_arr_cut_xx)\n",
    "\n",
    "# np.min(stress_arr_cut)\n",
    "\n",
    "np.max(energy_arr_cut_stress_xx)\n",
    "np.max(stress_arr_cut_xx)\n",
    "np.min(stress_arr_cut_xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(energy_arr_cut_stress_xx, stress_arr_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cropped_energies = [x for x in energy_arr if x <= 0 and  x >= -150]\n",
    "cutoff_top = 0.25\n",
    "cutoff_bottom = -0.25\n",
    "\n",
    "cropped_forces_x = forces_arr_x[np.where(np.logical_and(forces_arr_x < cutoff_top, forces_arr_x > cutoff_bottom))]\n",
    "cropped_forces_y = forces_arr_y[np.where(np.logical_and(forces_arr_y < cutoff_top, forces_arr_y > cutoff_bottom))]\n",
    "cropped_forces_z = forces_arr_z[np.where(np.logical_and(forces_arr_z < cutoff_top, forces_arr_z > cutoff_bottom))]\n",
    "# np.min(cropped_forces_x)\n",
    "\n",
    "# cropped_forces_x = np.where((forces_arr_x <= cutoff_top) or (forces_arr_x >= cutoff_bottom))\n",
    "# cropped_forces_y = np.where((forces_arr_y <= cutoff_top) or (forces_arr_y >= cutoff_bottom))\n",
    "# cropped_forces_z = np.where((forces_arr_z <= cutoff_top) or (forces_arr_z >= cutoff_bottom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# n, bins, patches = plt.hist(cropped_forces_x, bins = 'auto', facecolor = 'green')\n",
    "\n",
    "\n",
    "kwargs = dict(histtype='stepfilled', alpha=0.3, bins=100)\n",
    "\n",
    "\n",
    "plt.hist(cropped_forces_x, **kwargs)\n",
    "plt.hist(cropped_forces_y, **kwargs)\n",
    "plt.hist(cropped_forces_z, **kwargs)\n",
    "\n",
    "# plt.hist(cropped_forces_z, bins = 50, facecolor = 'steelblue', edgecolor = 'none')\n",
    "# ax.set_xlabel(\"{}\".format(\"Energy\"))\n",
    "# ax.set_xlim([-100,100])\n",
    "# ax.set_ylabel(\"Counts\")\n",
    "# plt.tight_layout()\n",
    "plt.show()\n",
    "# plt.savefig(\"Figures/{}.pdf\".format(name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(forces_arr_y, forces_arr_x, bins=50, cmap='Blues')\n",
    "plt.xlim([-0.1,0.1])\n",
    "plt.ylim([-0.1,0.1])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate Forces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_forces  =  separate_forces(forces_arr)\n",
    "print(sep_forces)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import pandas dataframe\n",
    "Provide the ``overwrite == True`` case to rerun the creation of the dataframe, else if ``overwrite == False`` imports it from the saved .pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_df(\"geo_opt\", overwrite = True)\n",
    "display(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Histograms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Energy Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_1d(df, quantity = 'energy', bin = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df['stress_xx'])\n",
    "\n",
    "display(df[df['stress_xx'] > 200])\n",
    "histogram_1d(df, quantity = 'stress_zz', bin = 200, xrange= [-20, 20])\n",
    "histogram_1d(df, quantity = 'stress_zy', bin = 200, xrange= [-20, 20])\n",
    "histogram_1d(df, quantity = 'stress_zy', bin = 200, xrange= [-20, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_arr = separate_forces(df['forces'].to_numpy())    \n",
    "# print(force_arr)\n",
    "# print(force_arr[20000])\n",
    "force = get_coordinate(array= force_arr, axis = \"x\")\n",
    "plt.hist(force, bins= 20)\n",
    "# plt.hist(force, histtype='step')\n",
    "\n",
    "#  n, bins, patches = ax.hist(force, bins = bin)\n",
    "#     ax.set_xlabel(\"{} {}\".format(\"Force\", axis))\n",
    "#     ax.set_xlim(xrange)\n",
    "#     ax.set_ylabel(\"Counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_1d_force(df, axis = 'x', bin = 10, xrange = [0, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_force_combined(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = df[\"forces\"].to_numpy()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "force_arr = separate_forces(var)    \n",
    "\n",
    "force = abs_forces_per_run(var)\n",
    "print(type(force))\n",
    "                            \n",
    "n, bins, patches = plt.hist(force)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_forces_per_run(var_forces= df[\"forces\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_arr, stress_arr, forces_arr = create_arr(\"geo_opt_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(energy_arr)\n",
    "# print(forces_arr)\n",
    "\n",
    "print(len(forces_arr))\n",
    "print(len(energy_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_entries = df[df['energy'] > 1000]\n",
    "print(positive_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_df(path = \"df_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)\n",
    "print(df.energy.max())\n",
    "print(df.energy.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_1d_force(df, axis = 'x', bin = 500, xrange = [-150, 150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_1d(df = df, quantity = \"force_x\", bin = 500, xrange = [-150,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_arr = separate_forces(var2)\n",
    "  # print(force_arr)\n",
    "\n",
    "  print(force_arr[1])\n",
    "\n",
    "  x_forces = get_coordinate(array= force_arr, axis = \"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_2d_energy_stress(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_1d(df = df, quantity = \"energy\", bin=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df['force_1'])\n",
    "np.where(pd.isna(df['force_1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"geo_opt/2_spg01.json.bz2\"\n",
    "path = \"geo_opt/ml_3_AB2C4.json.bz2\"\n",
    "quantity = []\n",
    "path_of_directory = 'geo_opt'\n",
    "desired_quantity = 'energy'\n",
    "\n",
    "# df_data = pd.DataFrame(columns = ['structure', 'force_1', 'force_2', 'stress_xx', 'stress_xy', 'stress_xz', \"stress_yx\", \"stress_yy\", 'stress_yz', 'stress_zx', 'stress_zy', 'stress_zz'])\n",
    "\n",
    "df_data = pd.DataFrame(columns=['run', 'energy', 'force_1', 'force_2', 'stress_xx', 'stress_xy', 'stress_xz', 'stress_yx', 'stress_yy', 'stress_yz', 'stress_zx', 'stress_zy', 'stress_zz'])\n",
    "# file_data = json.load(bz2.open(path, \"rb\"))\n",
    "# print(file_data)\n",
    "\n",
    "\n",
    "def retrieve_forces(force_array):\n",
    "    force_1, force_2 = force_array[0], force_array[1]\n",
    "    return force_1, force_2\n",
    "\n",
    "\n",
    "\n",
    "with bz2.BZ2File(path) as file:\n",
    "    for line in file:\n",
    "        line = line.decode().strip()\n",
    "        if line in {\"[\", \"]\"}:\n",
    "            continue\n",
    "        if line.endswith(\" \"):\n",
    "            line = line[:-1]\n",
    "        entity =json.loads(line)\n",
    "        print(entity)\n",
    "        for runs in entity.keys():\n",
    "            for item in entity[runs]:\n",
    "                struc = Structure.from_dict(item['structure'])\n",
    "                force_1, force_2 = retrieve_forces(item['forces'])\n",
    "                stress = item['stress']\n",
    "    \n",
    "                energy = item['energy']\n",
    "\n",
    "                data_run = pd.DataFrame({'run': runs,\n",
    "                                         \"structure\": [struc],\n",
    "                                         \"energy\": energy, \n",
    "                                         \"force_1\": [force_1], \"force_2\": [force_2], \n",
    "                                         'stress_xx': [stress[0][0]], 'stress_xy': [stress[0][1]], 'stress_xz':[stress[0][2]], \n",
    "                                         'stress_yx': [stress[1][0]], 'stress_yy': [stress[1][1]], 'stress_yz': [stress[1][2]], \n",
    "                                         'stress_zx': [stress[2][0]], 'stress_zy': [stress[2][1]], 'stress_zz': [stress[2][2]]})\n",
    "\n",
    "                data_run = pd.DataFrame(data_run)\n",
    "                df_data = pd.concat([df_data, data_run])\n",
    " \n",
    "\n",
    "df_data.memory_usage()\n",
    "\n",
    "df_data.reset_index(inplace=True, drop =True)\n",
    "cum_series = df_data.groupby('run').cumcount()\n",
    "cum_series = cum_series.astype(str)\n",
    "df_data['run'] = df_data['run'] + \"_\" + cum_series\n",
    "\n",
    "display(df_data)\n",
    "        \n",
    "\n",
    "def plotting_function(df, desired_quantity, savename):\n",
    "        counts, bins = np.histogram(df[desired_quantity])\n",
    "        plt.hist(bins[:-1], bins, weights = counts)\n",
    "        \n",
    "        plt.savefig(\"Figures/{}.pdf\".format(savename))\n",
    "\n",
    "\n",
    "# print(dtype(df_data['energy']))\n",
    "\n",
    "print(df_data.dtypes)\n",
    "\n",
    "energy = df_data['energy'].to_numpy()\n",
    "# print(energy)\n",
    "stress_xx = df_data['stress_xx'].to_numpy()\n",
    "\n",
    "# histo = np.histogram2d(energy, stress_xx, bins = (20, 20))\n",
    "# print(type(histo))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # fig, ax = plt.subplots()\n",
    "    # hist = ax.hist2d(var1, var2, bins = (bin, bin), cmap = plt.cm.jet)\n",
    "    # fig.colorbar(hist)\n",
    "\n",
    "    # fig.tight_layout()\n",
    "    # fig.savefig(\"Figures/{}.pdf\".format(savename_fig))\n",
    "    # plt.show()  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plt.imshow(histo)\n",
    "\n",
    "# plotting_function(df_data, \"energy\", \"energy_dist\")\n",
    "\n",
    "\n",
    "\n",
    "#         # Get all the keys (runs)\n",
    "#         # print(entity.keys())\n",
    "\n",
    "#         for runs in entity.keys():\n",
    "#             # The argument in entity specifies the run\n",
    "#             for i in entity[runs]:                    \n",
    "# #                 print(i.keys())\n",
    "#                 value = i[desired_quantity]\n",
    "#                 forces = i['forces']\n",
    "#                 stress = i['stress']\n",
    "#                 structure = i['structure']\n",
    "#                 energy = i['energy']\n",
    "#                 # print(forces)\n",
    "#                 quantity.append(value)\n",
    "                \n",
    "# print(quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_quantity(directory, desired_quantity):\n",
    "    # quantity can be structure, energy, forces, stress\n",
    "#     path = \"geo_opt/2_spg01.json.bz2\"\n",
    "    quantity = []\n",
    "#     ext = (\".bz2\")\n",
    "    print(\"Number of files in directory: {}\".format(len(os.listdir(directory))))\n",
    "    file_names = os.listdir(directory)\n",
    "    # print(file_names)\n",
    "#     for files in os.listdir(directory):\n",
    "    for files in file_names:\n",
    "        print(\"Current file selected: {}\".format(files))\n",
    "        with bz2.BZ2File(\"{}/{}\".format(directory,files)) as file:\n",
    "            for line in file:\n",
    "                line = line.decode().strip()\n",
    "                if line in {\"[\", \"]\"}:\n",
    "                    continue\n",
    "                if line.endswith(\" \"):\n",
    "                    line = line[:-1]\n",
    "                entity =json.loads(line)\n",
    "\n",
    "                # Get all the keys (runs)\n",
    "                # print(entity.keys())\n",
    "\n",
    "                for runs in entity.keys():\n",
    "                    # The argument in entity specifies the run\n",
    "                    for i in entity[runs]:                    \n",
    "#                         print(i.keys())\n",
    "                        value = i[desired_quantity]\n",
    "                        quantity.append(value)\n",
    "#                         forces = i['forces']\n",
    "#                         stress = i['stress']\n",
    "#                         structure = i['structure']\n",
    "#                         energy = i['energy']\n",
    "#                         print(forces)\n",
    "                \n",
    "    with open(\"{}.txt\".format(desired_quantity), 'w') as f:\n",
    "        for s in quantity:\n",
    "            f.write(str(s) + '\\n')\n",
    "\n",
    "    return quantity\n",
    "\n",
    "\n",
    "energy = return_quantity('geo_opt','energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"energy.txt\", 'r') as f:\n",
    "    energy = [line.rstrip('\\n') for line in f]\n",
    "    print(energy)\n",
    "\n",
    "# print(energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, bins = np.histogram(energy)\n",
    "plt.hist(bins[:-1], bins, weights = counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8460dbfb2f2f68418c6c6bf9581ab4fa4f4429bad5658983f4f8584321b9bbd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
